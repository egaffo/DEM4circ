---
title: "Source dataset characteristics"
author: "Enrico Gaffo"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: yes
    toc_float: yes
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
outdir <- "source_ds_characteristics"
dir.create(path = outdir, showWarnings = F, recursive = T)

knitr::opts_chunk$set(echo = TRUE, 
                      fig.path = file.path(outdir, "Figs/"), 
                      dev = c("png", "svglite", "pdf"))

library(data.table)
library(qs)
library(DT)
library(ComplexHeatmap)
library(scales)
library(ggplot2)
library(ggrepel)
library(ggthemes)
library(patchwork)
library(ggbeeswarm)

library(BiocParallel)

library(edgeR)
```

```{r}
## output file path
dir.create(path = outdir, showWarnings = F, recursive = T)

## input data
ds_names <- c("DM1", "IDC", "IPF", "MS")
unfilt_ds_files <- setNames(paste0("../../data/", 
                                   ds_names, 
                                   "_unfiltered_CirComPara2_circbjr.csv"), 
                            ds_names)

ds_meta_files <- setNames(paste0("../../data/", 
                                 ds_names, 
                                 "_meta.csv"), 
                          ds_names)

trimmed_source_dataset_files <- file.path("..", "simulations", "semiparametric", "simdata",
                                    paste0(ds_names, "_", 
                                    "trimmed_source_dataset.qs"))

names(trimmed_source_dataset_files) <- ds_names

PC_data_file <- "../../data/PMID35078526_rawCIRI2output.tsv"
```

```{r}
nWorkers <- multicoreWorkers()
```

# Data sets characteristics

## Source data sets

```{r}
## read unfiltered data
source_ds_dt <- 
    rbindlist(lapply(unfilt_ds_files,
                     function(x, min_samples = 0){
                         y <- fread(x, data.table = F)
                         m <- as.matrix(y[, -1])
                         rownames(m) <- y[, 1]
                         melt(as.data.table(m[rowSums(m > 0) >= min_samples, ], 
                                            keep.rownames = "circ_id"),
                              id.vars = "circ_id", variable.name = "sample_id")
                     }
    ), 
    idcol = "DS")

source_ds_meta <- 
    rbindlist(lapply(ds_meta_files,
                     fread), 
              idcol = "DS", use.names = T)
```

### CircRNAs per number of samples

Exact number of samples in which a circRNA has been detected.  

```{r, fig.width=6, fig.height=5}
plot.dt <- 
    source_ds_dt[value > 0, 
                 .(n_samples = .N), 
                 by = .(DS, circ_id)][, .(n_circs = .N), 
                                      by = .(DS, n_samples)]

plot.dt[order(-n_samples), cum_circs := cumsum(n_circs), by = .(DS)]

# ggplot(plot.dt,
#        aes(x = factor(n_samples),
#            y = n_circs)) +
#     geom_point(aes(color = DS)) +
#     scale_color_tableau(direction = -1) +
#     facet_wrap(~ DS, scales = "free", ncol = 1) +
#     labs(y = "Number of circRNAs", x = "Number of samples") +
#     theme_classic() +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))
```

Minimum number of samples in which a circRNA has been detected.  

```{r, fig.width=6, fig.height=5}
# ggplot(plot.dt,
#        aes(x = factor(n_samples), 
#            y = cum_circs)) +
#     geom_point(aes(color = DS)) +
#     scale_color_tableau(direction = -1) +
#     facet_wrap(~ DS, scales = "free", ncol = 1) +
#     labs(y = "Cumulative number of circRNAs", 
#          x = "Cumulative number of samples") + # "(\u2265)"
#     theme_classic() +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))
```

### Mean expression per number of samples

```{r, fig.width=6.5, fig.height=8.8}
plot.dt <- 
    merge(source_ds_dt[value > 0, .(n_samples = .N), by = .(DS, circ_id)], 
          source_ds_dt[, .(mean_BJR = mean(value)), by = .(DS, circ_id)], 
          by = c("DS", "circ_id"))
```

```{r, fig.height=8.5, fig.width=3}
bjr_box_plot <-
    ggplot(plot.dt,
           aes(y = factor(n_samples, levels = max(plot.dt$n_samples):1, ordered = T),
               x = mean_BJR, 
               color = DS)) +
    geom_boxplot(outlier.size = .3, #outlier.alpha = .5,
                 outlier.shape = NA, # this removes the outliers
                 varwidth = F, 
                 notch = F, position = position_dodge2(preserve = "single")) +
    scale_x_log10(label = label_comma(accuracy = 1)) +
    scale_color_tableau(direction = -1) +
    # facet_wrap(~ DS, scales = "fixed", nrow = 1) +
    labs(x = "Mean BJR", y = "Number of samples") +
    theme_bw() +
    theme(legend.position = "none",
        axis.text.x = element_text(angle = 90,
                                     hjust = 1,
                                     vjust = .5),
          panel.grid.minor.y = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.spacing = unit(.1, "lines"))

ncircs_plot <-
    ggplot(plot.dt[, .(n_circs = .N), by = .(DS, n_samples)],
           aes(x = factor(n_samples, levels = max(plot.dt$n_samples):1, ordered = T), 
               y = n_circs, 
               # fill = DS, 
               color = DS)) +
    # geom_col(position = position_dodge2(preserve = "single")) +
    geom_line(aes(group = DS)) +
    scale_color_tableau(name = "Dataset", direction = -1) +
    geom_point() +
    coord_flip() +
    scale_y_continuous("Number of\ncircRNAs") +
    # scale_y_sqrt("Number of\ncircRNAs") +
    # scale_y_log10("Number of\ncircRNAs") +
    theme_bw() +
    theme(legend.position = c(.65, .2),
          legend.background = element_blank(),
        axis.text.x = element_text(angle = 90,
                                     hjust = 1,
                                     vjust = .5),
          panel.grid.minor.y = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(), 
          panel.spacing = unit(.1, "lines"))

wrap_plots(bjr_box_plot +
               theme(plot.margin = margin(0, 0, 0, 0)), 
           ncircs_plot + 
               labs(x = NULL) +
               # guides(color = "none") +
               theme(axis.text.y = element_blank(),
                     axis.ticks.y = element_blank(), 
                     plot.background = element_blank(),
                     plot.margin = margin(0, 0, 0, 0)), 
           # guides = "collect", 
           nrow = 1, 
           widths = c(.6, .4)) &
    # scale_color_tableau(name = "Study", direction = -1) &
    theme(#legend.position = "top", 
          text = element_text(size = 10))
```

### Unfiltered data sets {.tabset}

#### BJR proportion 

```{r, fig.width=4, fig.height=3.5}
source_hist_cnt <- 
    source_ds_dt[, .(histBJR = .N), 
             by = .(DS, BJR = value)][, Frac := histBJR / sum(histBJR), 
                                  by = .(DS)][]
plot_dt <- source_hist_cnt[, .(AvgFrac = mean(Frac)),
                    by = .(DS, BJR)]

ds_stats <- 
    source_ds_dt[, .(nSamples = .N), 
                 by = .(DS, circ_id)][, .(nSamples = head(nSamples, 1),
                                          nCircs = .N), by = DS]

ch_p <- 
    ggplot(plot_dt, aes(x = BJR, y = AvgFrac)) + 
    geom_col(position = "identity", alpha = 1, aes(fill = DS)) +
    # facet_wrap(facets = ~ DS, ncol = 1, scales = "free_y") +
    facet_grid(rows = vars(DS)) +
    coord_cartesian(xlim = c(0, 15)) +
    geom_label(data = ds_stats, 
               size = 3,
               aes(x = 5, y = .5, 
                   label = paste("# samples:", nSamples, "\n# circRNAs:", comma(nCircs))), hjust = 0) +
    labs(x = "Backsplice-junction reads") +
    scale_y_continuous("Count matrix fraction (%)", 
                       labels = function(x)round(as.numeric(x)*100)) + #labels = percent
    scale_x_continuous(breaks = 0:15, 
                       labels = 0:15) +
    scale_fill_tableau(direction = -1) +
    theme_bw() +
    theme(legend.position = "none", 
          axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5), 
          plot.margin = unit(x = c(.1, .1, .1, .1), units = "lines"), 
          strip.text = element_blank(), 
          panel.grid.major.x = element_blank(),
          panel.grid.minor = element_blank(),
          strip.background = element_blank())

ls_bxp <- 
    ggplot(source_ds_dt[, .(LibSize = sum(value)), by = .(DS, sample_id)],
           aes(x = "", y = LibSize)) +
    geom_boxplot(varwidth = T,
                 notch = F,
                 outlier.size = .5,
                 aes(color = DS)) + #, outlier.shape = NA
    # geom_quasirandom(groupOnX = T, varwidth = T, alpha = .5, aes(fill = LibSize), shape = 21) +
    # geom_violin(aes(color = DS), 
    #             trim = T, 
    #             draw_quantiles = c(.25, .5, .75)) +
    # scale_fill_viridis_c() +
    scale_x_discrete(name = NULL) +
    scale_y_log10(labels = function(x)sub("000$", "K", x)) +
    scale_color_tableau(direction = -1) +
    labs(x = NULL, y = "Library size") +
    coord_flip() +
    # facet_wrap(facets = ~ DS, ncol = 1) + #, scales = "free_x"
    facet_grid(rows = vars(DS)) +
    theme_bw() +
    theme(legend.position = "none",
          axis.ticks.y = element_blank(), 
          panel.grid.major.y = element_blank(),
          plot.margin = unit(x = c(.1, .1, .1, .1), units = "lines"))

ch_p + ls_bxp +
    plot_layout(widths = c(3, 1))
```

#### Sparsity

Sparsity for each sample is calculated counting the circRNAs with zero count that have been detected in other samples of the same data set.  

```{r, fig.width=3.5, fig.height=2.5}
plot_dt <- 
    merge(merge(source_ds_dt[, .(Sparsity = sum(value == 0)/length(value)), 
                             by = .(DS, sample_id)],
                source_ds_dt[, .(LibSize = sum(value)), 
                             by = .(DS, sample_id)], 
                by = c("DS", "sample_id")),
          source_ds_dt[, .N, by = .(DS, circ_id)][, .(Features = .N), by = DS],
          by = "DS")

# ggplot(plot_dt, 
#        aes(x = LibSize, y = Sparsity * 100, color = DS)) +
#     geom_point(alpha = .5, size = 2) +
#     geom_smooth(method = "glm", 
#                 # group = 1, 
#                 # color = "black", 
#                 linetype = "dashed", 
#                 se = F) +
#     scale_x_continuous("Library size (BJRs)", labels = comma) +
#     scale_y_continuous("Sparsity (%)", limits = c(0, 100)) +
#     scale_color_tableau(name = "Dataset", direction = -1) +
#     # scale_size(name = "CircRNAs", breaks = sort(plot_dt$Features)) +
#     guides(color = guide_legend(nrow = 1, 
#                                 title.position = "top", 
#                                 title.hjust = .5)) +
#     theme_bw() +
#     theme(legend.position = c(.5, .175), 
#           legend.background = element_rect(colour = "grey55"),
#           legend.margin = margin(t = .1, r = .2, b = .1, l = .2, unit = "lines"),
#           panel.grid.minor = element_blank())
```

Below, sparsity is calculated counting the fraction of zeros in the data set matrix.  
Mean library size is the mean sum of BJRs in each sample of the data set.  

```{r, fig.width=4.5, fig.height=2.5}
plot_dt <- 
    merge(merge(source_ds_dt[, .(Sparsity = sum(value == 0)/length(value)), by = DS],
                source_ds_dt[, .(LibSize = sum(value)), 
                             by = .(DS, sample_id)][, .(`Mean library size` = mean(LibSize)), 
                                                    by = DS], 
                by = "DS"),
          source_ds_dt[, .N, by = .(DS, circ_id)][, .(Features = .N), by = DS],
          by = "DS")

cortest <- cor.test(x = plot_dt$`Mean library size`, y = plot_dt$Sparsity, method = "pearson")

# cortest$p.value
cortest$estimate
```


```{r, fig.width=4.5, fig.height=2.5}
ggplot(plot_dt, 
       aes(x = `Mean library size`, y = Sparsity * 100, color = DS)) +
    geom_smooth(method = "glm", group = 1, color = "black", linetype = "dashed", se = T) +
    geom_point(aes(size = Features)) +
    geom_label_repel(aes(label = DS), show.legend = F) +
    annotate(geom = "label", x = 25000, y = 25, 
             label = paste0("P=", 
                           round(cortest$p.value, 2),
                           ", r=",
                           round(cortest$estimate, 2))) +
    # scale_x_log10() +
    scale_x_continuous(labels = comma) +
    scale_y_continuous("Sparsity (%)", limits = c(0, 100)) +
    scale_color_tableau(direction = -1) +
    scale_size(name = "CircRNAs", breaks = sort(plot_dt$Features)) +
    guides(color = "none") +
    theme_bw() +
    theme(legend.position = "right",
          panel.grid.minor = element_blank())
```

```{r}
datatable(plot_dt)
```

### Downsampling {.tabset}

#### Sparsity  

```{r}
## get non-zero counts of the matrix
## compute the amount of reads to remove in each sample
## to downsize them by 25%, 50% and 75%
sample_downsizes <-
  source_ds_dt[, 
               .(Depth = sum(value)), 
               by = .(DS, 
                      sample_id)][, `:=`(`75%` = ceiling(Depth * .25),
                                         `50%` = ceiling(Depth * .5),
                                         `25%` = ceiling(Depth * .75))][]

sample_downsizes_l <-
  melt(sample_downsizes, id.vars = c("DS", "sample_id"), 
       variable.name = "Down to", 
       value.name = "Diff")

downsized_samples <- 
  rbindlist(apply(X = sample_downsizes_l, 
      MARGIN = 1, 
      FUN = function(x, y){
        y <- y[DS == x[1] & sample_id == x[2]]
        
        ## select random XX elements (with replacement, 
        ## one element can be selected more than once
        ## but no more than its reads
        circ_list <- 
          c(y[value == 1, circ_id], 
            unlist(apply(y[value > 1], 
                         MARGIN = 1, 
                         FUN = function(z){
                           rep(z[2], as.integer(z[4]))
                         }))
          )
        
        ## subtract the counts
        merge(y,
              data.table(t(table(sample(circ_list, as.integer(x[4]), 
                                        replace = F))))[, .(circ_id = V2, 
                                                            Resize = N)],
              by = "circ_id", 
              all = T)[, Downsampling := x[3]][is.na(Resize), Resize := 0]
        
      }, y = source_ds_dt)
  )

downsized_samples[Downsampling != "Depth", 
                 `:=`(value = value - Resize)]

downsize_stats <- 
  downsized_samples[value > 0, 
                        .(Depth = sum(value),
                          meanBJR = mean(value),
                          medianBJR = median(value),
                          nCircs = .N), 
                        by = .(Downsampling, DS, 
                               sample_id)]
```


```{r, fig.width=6.5, fig.height=4.5}
plot_dt <- 
  merge(
    merge(downsized_samples[, .(Sparsity = sum(value == 0) / .N), 
                            by = .(Downsampling, DS)],
          downsize_stats[, .(avgDepth = mean(Depth)), 
                         by = .(Downsampling, DS)]
    ),
    downsized_samples[value > 0, 
                          .(nCircs = length(unique(circ_id))), 
                          by = .(Downsampling, DS)])

plot_dt[Downsampling == "Depth", Downsampling := "100%"]
plot_dt$Downsampling <- factor(plot_dt$Downsampling,
                               levels = c("100%", "75%", "50%", "25%"),
                               ordered = T)

corfunc <- 
  function(x, y){
    ct <- cor.test(x = x, y = y, method = "pearson")
    list(Pval = ct$p.value, Cor = ct$estimate)
  }

cortests <- plot_dt[, corfunc(x = avgDepth, y = Sparsity), 
                    by = .(Downsampling)]

cortests <- 
  merge(cortests,
        plot_dt[, .(avgDepth = mean(avgDepth)), by = .(Downsampling)])

ggplot(plot_dt, aes(x = avgDepth, y = Sparsity *100, color = DS)) +
  geom_smooth(aes(group = Downsampling),
              color = "black", linetype = "dashed",
              method = "glm", se = T) +
  geom_point(aes(fill = log10(nCircs), size = log10(nCircs)), shape = 21) +
  geom_label_repel(aes(label = DS), show.legend = F) +
  # facet_grid(rows = vars(Downsampling), scales = "free_x") +
  facet_wrap(facets = ~ Downsampling, dir = "h", scales = "free_x") +
  labs(x = "Mean library size") +
  scale_x_continuous(labels = comma) +
  scale_y_continuous("Sparsity (%)", limits = c(0, 100)) +
  scale_color_tableau(name = "Dataset", direction = -1, guide = "none") +
  scale_fill_viridis_c("Log10(circRNAs)", option = "B") +
  # scale_size(name = "Log10(circRNAs)", breaks = sort(plot_dt$nCircs)) +
  scale_size(name = "Log10(circRNAs)") +
  geom_label(data = cortests, color = "black", hjust = .5,
            aes(y = 15, 
                label = paste0("P=", round(Pval, 2), 
                              ", r=", round(Cor, 2)))) +
  theme_bw() +
  theme(legend.position = "right",
        panel.grid.minor = element_blank())
```

#### Saturation plot (NOISeq)

The "Saturation" plot shows the number of features in the genome detected with more than k counts with the sequencing depth of the sample, and with higher and lower simulated sequencing depths.  
The number of detected features per biotype at increasing sequencing depths and also the new detections per each million of new sequencing reads.  

Sequencing saturation is dependent on the library complexity and sequencing depth. Different cell types will have different amounts of RNA and thus will differ in the total number of different transcripts in the final library (also known as library complexity). As sequencing depth increases, more genes are detected, but this reaches saturation at different sequencing depths depending on cell type.   

The lines show how the number of detected features increases with depth. When the number of samples to plot is 1 or 2, bars indicating the number of new features detected when increasing the sequencing depth in one million of reads are also drawn. In that case, lines values are to be read in the left Y axis and bar values in the right Y axis. If more than 2 samples are to be plotted, it is difficult to visualize the new detection bars, so only the lines are shown in the plot.  
Left Y axis shows the number of detected genes with more than 0 counts at each sequencing depth, represented by the lines. The solid point in each line corresponds to the real available sequencing depth. The other sequencing depths are simulated from this total sequencing depth. The bars are associated to the right Y axis and show the number of new features detected per million of new sequenced reads at each sequencing depth.  
The legend in the gray box also indicates the percentage of total features detected with more than k=0 counts at the real sequencing depth.  
Up to twelve samples can be displayed in this plot.  

```{r, fig.width=6.5, fig.height=4.5}
ds_mats_l <- 
  sapply(split(source_ds_dt, by = "DS", keep.by = F), 
         function(x){
           as.matrix(data.frame(dcast(x, formula = circ_id ~ sample_id, 
                                      value.var = "value", fill = 0), 
                                row.names = "circ_id"))
         }, simplify = F, 
         USE.NAMES = T)

suppressPackageStartupMessages(library(NOISeq))
mydata_dm1 <- ExpressionSet(assayData = ds_mats_l$DM1)
mysaturation_dm1 <- dat(mydata_dm1, k = 0, ndepth = 7, type = "saturation")

mydata_idc <- ExpressionSet(ds_mats_l$IDC)
mysaturation_idc <- dat(mydata_idc, k = 0, ndepth = 7, type = "saturation")

mydata_ipf <- ExpressionSet(ds_mats_l$IPF)
mysaturation_ipf <- dat(mydata_ipf, k = 0, ndepth = 7, type = "saturation")

mydata_ms <- ExpressionSet(ds_mats_l$MS)
mysaturation_ms <- dat(mydata_ms, k = 0, ndepth = 7, type = "saturation")
```

```{r, fig.width=6.5, fig.height=4.5}
sat_dat <- 
  rbindlist(sapply(list(DM1 = mysaturation_dm1,
                        IDC = mysaturation_idc, 
                        IPF = mysaturation_ipf,
                        MS = mysaturation_ms), 
                   function(mysat){
                     merge(melt(rbindlist(sapply(mysat@dat$depth, 
                                                 function(x){data.table(t(x))}, 
                                                 simplify = F), 
                                          idcol = "sample_id"), 
                                id.vars = "sample_id", variable.name = "Sampling", 
                                value.name = "Depth"),
                           melt(rbindlist(sapply(mysat@dat$saturation$global, 
                                                 function(x){data.table(t(x))}, 
                                                 simplify = F), 
                                          idcol = "sample_id"), 
                                id.vars = "sample_id", variable.name = "Sampling", 
                                value.name = "CircRNAs"), 
                           by = c("sample_id", "Sampling"))
                   }, simplify = F, USE.NAMES = T), 
            idcol = "DS")

sat_dat <- merge(sat_dat, source_ds_meta, by = c("DS", "sample_id"))

ggplot(sat_dat, #[Sampling %in% paste0("V", 1:4)], 
       aes(x = Depth, y = CircRNAs, color = DS)) +
  geom_line(aes(group = sample_id), alpha = .5) +
  geom_point(alpha = 1, shape = 21, fill = "white") +
  geom_point(data = sat_dat[Sampling %in% "V4"], 
             alpha = .75, shape = 21, #size = 2.5, 
             aes(fill = DS)) +
  facet_wrap(facets = ~ DS, scales = "free") +
  scale_color_tableau(direction = -1, guide = "none") +
  scale_fill_tableau(direction = -1, guide = "none") +
  labs(x = "Library size (reads)", y = "Number of circRNAs detected") +
  theme_bw() +
  theme(panel.grid.minor = element_blank())
```

```{r, fig.width=6.5, fig.height=4.5}
ggplot(sat_dat, #[Sampling %in% paste0("V", 1:4)], 
       aes(x = Depth, y = CircRNAs, color = DS)) +
  geom_line(aes(group = sample_id), alpha = .5) +
  geom_point(alpha = 1, shape = 21, fill = "white") +
  geom_point(data = sat_dat[Sampling %in% "V4"], 
             alpha = .75, shape = 21, #size = 2.5, 
             aes(fill = DS)) +
  # facet_wrap(facets = ~ DS, scales = "free") +
  scale_color_tableau(name = "Data set", direction = -1) +
  scale_fill_tableau(name = "Data set", direction = -1) +
  labs(x = "Library size (reads)", y = "Number of circRNAs detected") +
  theme_bw() +
  theme(panel.grid.minor = element_blank(), legend.position = c(.7, .3))
```


### 3 samples filter {.tabset}

Data sets after filtering according to circRNAs detected in 3 or more samples.  

#### Within condition correlation of samples

Original data sets after sample selection and circRNA preliminary filters.  

```{r}
trimmed_source_dataset_l <- lapply(trimmed_source_dataset_files, qread)

within_cond_corr <- function(ds, cor.meth = "pearson"){
    
    g1 <- rownames(ds$samples)[as.integer(ds$samples$group) == 1]
    g2 <- rownames(ds$samples)[as.integer(ds$samples$group) == 2]
    
    cor_g1 <- cor(x = ds$counts[, g1], method = cor.meth)
    cor_g2 <- cor(x = ds$counts[, g2], method = cor.meth)
    
    list(G1_cor = cor_g1[upper.tri(cor_g1)],
      G2_cor = cor_g2[upper.tri(cor_g2)])
}

# data.frame(lapply(trimmed_source_dataset_l, within_cond_corr, cor.meth = "pearson"))
cor_lists <- sapply(trimmed_source_dataset_l, within_cond_corr, cor.meth = "pearson", simplify = F)
cor_dt <- rbindlist(lapply(cor_lists, function(x)rbind(data.table(Group = "G1", CorPear = x[[1]]),
                                   data.table(Group = "G2", CorPear = x[[2]]))), 
          idcol = "DS")
```

```{r}
datatable(cor_dt, rownames = F, filter = "top")
```

```{r}
datatable(cor_dt[, .(Min = min(CorPear), Max = max(CorPear)), by = .(DS, Group)])
```

#### 3S filter BJR proportion 

```{r, fig.width=4, fig.height=3.5}
circ_id3s <- source_ds_dt[value > 0, .N, by = .(DS, circ_id)][N > 2, circ_id]

source_hist_cnt <- 
    source_ds_dt[circ_id %in% circ_id3s, 
                 .(histBJR = .N), 
             by = .(DS, BJR = value)][, Frac := histBJR / sum(histBJR), 
                                  by = .(DS)][]
plot_dt <- source_hist_cnt[, .(AvgFrac = mean(Frac)),
                    by = .(DS, BJR)]

ds_stats <- 
    source_ds_dt[circ_id %in% circ_id3s, 
                 .(nSamples = .N), 
                 by = .(DS, circ_id)][, .(nSamples = head(nSamples, 1),
                                          nCircs = .N), by = DS]

ch_p <- 
    ggplot(plot_dt, aes(x = BJR, y = AvgFrac)) + 
    geom_col(position = "identity", alpha = 1, aes(fill = DS)) +
    # facet_wrap(facets = ~ DS, ncol = 1, scales = "free_y") +
    facet_grid(rows = vars(DS)) +
    coord_cartesian(xlim = c(0, 15)) +
    geom_label(data = ds_stats, 
               size = 3,
               aes(x = 5, y = .5, 
                   label = paste("# samples:", nSamples, "\n# circRNAs:", comma(nCircs))), hjust = 0) +
    labs(x = "Backsplice-junction reads") +
    scale_y_continuous("Count matrix fraction (%)", 
                       labels = function(x)round(as.numeric(x)*100)) + #labels = percent
    scale_x_continuous(breaks = 0:15, 
                       labels = 0:15) +
    scale_fill_tableau(direction = -1) +
    theme_bw() +
    theme(legend.position = "none", 
          axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5), 
          plot.margin = unit(x = c(.1, .1, .1, .1), units = "lines"), 
          strip.text = element_blank(), 
          panel.grid.major.x = element_blank(),
          panel.grid.minor = element_blank(),
          strip.background = element_blank())

ls_bxp <- 
    ggplot(source_ds_dt[, .(LibSize = sum(value)), by = .(DS, sample_id)],
           aes(x = "", y = LibSize)) +
    geom_boxplot(varwidth = T,
                 notch = F,
                 outlier.size = .5,
                 aes(color = DS)) + #, outlier.shape = NA
    # geom_quasirandom(groupOnX = T, varwidth = T, alpha = .5, aes(fill = LibSize), shape = 21) +
    # geom_violin(aes(color = DS), 
    #             trim = T, 
    #             draw_quantiles = c(.25, .5, .75)) +
    # scale_fill_viridis_c() +
    scale_x_discrete(name = NULL) +
    scale_y_log10(labels = function(x)sub("000$", "K", x)) +
    scale_color_tableau(direction = -1) +
    labs(x = NULL, y = "Library size") +
    coord_flip() +
    # facet_wrap(facets = ~ DS, ncol = 1) + #, scales = "free_x"
    facet_grid(rows = vars(DS)) +
    theme_bw() +
    theme(legend.position = "none",
          axis.ticks.y = element_blank(), 
          panel.grid.major.y = element_blank(),
          plot.margin = unit(x = c(.1, .1, .1, .1), units = "lines"))

ch_p + ls_bxp +
    plot_layout(widths = c(3, 1))
```

#### Sparsity

Data sets after filtering according to circRNAs detected in 3 or more samples.  

```{r, fig.width=4.5, fig.height=2.5}
plot_dt <- 
    merge(merge(source_ds_dt[circ_id %in% circ_id3s,
                             .(Sparsity = sum(value == 0)/length(value)), by = DS],
                source_ds_dt[circ_id %in% circ_id3s, 
                             .(LibSize = sum(value)), 
                             by = .(DS, sample_id)][, .(`Mean library size` = mean(LibSize)), 
                                                    by = DS], 
                by = "DS"),
          source_ds_dt[circ_id %in% circ_id3s, 
                       .N, by = .(DS, circ_id)][, .(Features = .N), by = DS],
          by = "DS")

cortest <- cor.test(x = plot_dt$`Mean library size`, y = plot_dt$Sparsity, method = "pearson")

# cortest$p.value
cortest$estimate

ggplot(plot_dt, 
       aes(x = `Mean library size`, y = Sparsity * 100, color = DS)) +
    geom_smooth(method = "glm", group = 1, color = "black", linetype = "dashed", se = T) +
    geom_point(aes(size = Features)) +
    geom_label_repel(aes(label = DS), show.legend = F) +
    annotate(geom = "label", x = 25000, y = 25, 
             label = paste0("P=", 
                           round(cortest$p.value, 2),
                           ", r=",
                           round(cortest$estimate, 2))) +
    # scale_x_log10() +
    scale_x_continuous(labels = comma) +
    scale_y_continuous("Sparsity (%)", limits = c(0, 100)) +
    scale_color_tableau(direction = -1) +
    scale_size(name = "CircRNAs", breaks = sort(plot_dt$Features)) +
    guides(color = "none") +
    theme_bw() +
    theme(legend.position = "right",
          panel.grid.minor = element_blank())
```

```{r}
datatable(plot_dt)
```

### Downsampling {.tabset}

#### Sparsity  

```{r}
circ_id_3sDs <- 
  source_ds_dt[value > 0, .N, 
                   by = .(DS, circ_id)][N > 2, ]

source_ds_dt_3sf <- 
  source_ds_dt[circ_id_3sDs[, .(DS, circ_id)], 
               on = c("DS", "circ_id")]

## get non-zero counts of the matrix
## compute the amount of reads to remove in each sample
## to downsize them by 25%, 50% and 75%
sample_downsizes <-
  source_ds_dt_3sf[, 
                   .(Depth = sum(value)), 
                   by = .(DS, 
                          sample_id)][, `:=`(`75%` = ceiling(Depth * .25),
                                             `50%` = ceiling(Depth * .5),
                                             `25%` = ceiling(Depth * .75))][]

sample_downsizes_l <-
  melt(sample_downsizes, id.vars = c("DS", "sample_id"), 
       variable.name = "Down to", 
       value.name = "Diff")

downsized_samples <- 
  rbindlist(apply(X = sample_downsizes_l, 
      MARGIN = 1, 
      FUN = function(x, y){
        y <- y[DS == x[1] & sample_id == x[2]]
        
        ## select random XX elements (with replacement, 
        ## one element can be selected more than once
        ## but no more than its reads
        circ_list <- 
          c(y[value == 1, circ_id], 
            unlist(apply(y[value > 1], 
                         MARGIN = 1, 
                         FUN = function(z){
                           rep(z[2], as.integer(z[4]))
                         }))
          )
        
        ## subtract the counts
        merge(y,
              data.table(t(table(sample(circ_list, as.integer(x[4]), 
                                        replace = F))))[, .(circ_id = V2, 
                                                            Resize = N)],
              by = "circ_id", 
              all = T)[, Downsampling := x[3]][is.na(Resize), Resize := 0]
        
      }, y = source_ds_dt_3sf)
  )

downsized_samples[Downsampling != "Depth", 
                 `:=`(value = value - Resize)]
# names(downsized_samples) <- apply(sample_downsizes_l, 1, paste0, collapse = ",")
```


```{r}
circ_id_3sDs <- 
  downsized_samples[value > 0, .N, 
                   by = .(Downsampling, DS, circ_id)][N > 2, ]

downsized_samples_3sf <- 
  merge(downsized_samples, 
        circ_id_3sDs[, .(Downsampling, DS, circ_id)])
```


```{r, fig.width=6.5, fig.height=4.5}
downsize_stats <- 
  downsized_samples_3sf[value > 0, 
                        .(Depth = sum(value),
                          meanBJR = mean(value),
                          medianBJR = median(value),
                          nCircs = .N), 
                        by = .(Downsampling, DS, 
                               sample_id)]

plot_dt <- 
  merge(
    merge(downsized_samples_3sf[, .(Sparsity = sum(value == 0) / .N), 
                               by = .(Downsampling, DS)],
          downsize_stats[, .(avgDepth = mean(Depth)), 
                         by = .(Downsampling, DS)]
    ),
    downsized_samples_3sf[value > 0, 
                         .(nCircs = length(unique(circ_id))), 
                         by = .(Downsampling, DS)])

plot_dt[Downsampling == "Depth", Downsampling := "100%"]
plot_dt$Downsampling <- factor(plot_dt$Downsampling,
                               levels = c("100%", "75%", "50%", "25%"),
                               ordered = T)

corfunc <- 
  function(x, y){
    ct <- cor.test(x = x, y = y, method = "pearson")
    list(Pval = ct$p.value, Cor = ct$estimate)
  }

cortests <- plot_dt[, corfunc(x = avgDepth, y = Sparsity), 
                    by = .(Downsampling)]

cortests <- 
  merge(cortests,
        plot_dt[, .(avgDepth = mean(avgDepth)), by = .(Downsampling)])

ggplot(plot_dt, aes(x = avgDepth, y = Sparsity *100, color = DS)) +
  geom_smooth(aes(group = Downsampling),
              color = "black", linetype = "dashed",
              method = "glm", se = T) +
  geom_point(aes(fill = log10(nCircs), size = log10(nCircs)), shape = 21) +
  geom_label_repel(aes(label = DS), show.legend = F) +
  # facet_grid(rows = vars(Downsampling), scales = "free_x") +
  facet_wrap(facets = ~ Downsampling, dir = "h", scales = "free_x") +
  labs(x = "Mean library size") +
  scale_x_continuous(labels = comma) +
  scale_y_continuous("Sparsity (%)", limits = c(0, 100)) +
  scale_color_tableau(name = "Dataset", direction = -1, guide = "none") +
  scale_fill_viridis_c("Log10(circRNAs)", option = "B") +
  # scale_size(name = "Log10(circRNAs)", breaks = sort(plot_dt$nCircs)) +
  scale_size(name = "Log10(circRNAs)") +
  geom_label(data = cortests, color = "black", hjust = .5,
            aes(y = 15, 
                label = paste0("P=", round(Pval, 2), 
                              ", r=", round(Cor, 2)))) +
  theme_bw() +
  theme(legend.position = "right",
        panel.grid.minor = element_blank())
```

#### Saturation plot (NOISeq)

The "Saturation" plot shows the number of features in the genome detected with more than k counts with the sequencing depth of the sample, and with higher and lower simulated sequencing depths.  
The number of detected features per biotype at increasing sequencing depths and also the new detections per each million of new sequencing reads.  

Sequencing saturation is dependent on the library complexity and sequencing depth. Different cell types will have different amounts of RNA and thus will differ in the total number of different transcripts in the final library (also known as library complexity). As sequencing depth increases, more genes are detected, but this reaches saturation at different sequencing depths depending on cell type.   

```{r}
# fullLibSize <- 
#   source_ds_dt[value > 0, .(nCircs = .N,
#                             LibSize = sum(value),
#                             medianBJR = median(value)),
#                by = .(DS, sample_id)]
# 
# 
# ggplot(fullLibSize, aes(x = LibSize, y = nCircs, color = DS)) +
#   geom_point(aes(size = medianBJR)) +
#   scale_color_tableau(direction = -1)# +
#   # scale_x_log10() +
#   # scale_y_log10()
# 
# ggplot(fullLibSize, aes(x = LibSize, y = nCircs, color = log2(medianBJR))) +
#   geom_point(aes(shape = DS)) +
#   scale_color_viridis_c(option = "B")
# 
# ggplot(fullLibSize, aes(x = LibSize, y = medianBJR, color = DS)) +
#   geom_point(aes(size = nCircs)) +
#   scale_color_tableau(direction = -1)
```

```{r}
# plot_dt <- merge(downsize_stats, source_ds_meta, by = c("DS", "sample_id"))
# 
# ggplot(plot_dt, aes(x = Depth, y = nCircs, color = DS)) +
#   geom_line(aes(group = sample_id)) +
#   geom_point(aes(size = medianBJR, shape = Downsampling)) +
#   scale_color_tableau(direction = -1) +
#   scale_x_log10() +
#   scale_y_log10() +
#   facet_wrap(facets = ~ DS, scales = "free")
# 
# ggplot(plot_dt, aes(x = Depth, y = nCircs, color = condition)) +
#   # geom_line(aes(group = sample_id)) +
#   geom_point(aes(size = medianBJR, shape = condition)) +
#   scale_shape_manual(values = 21:28) +
#   scale_color_tableau(direction = -1) +
#   scale_x_log10() +
#   scale_y_log10() +
#   # facet_wrap(facets = ~ DS, scales = "free")
#   facet_grid(rows = vars(Downsampling), cols = vars(DS))
# 
# 
# ggplot(downsize_stats, aes(x = Depth, y = nCircs, color = DS)) +
#   # geom_line(aes(group = sample_id)) +
#   geom_point(aes(size = medianBJR, shape = Downsampling)) +
#   scale_color_tableau(direction = -1) +
#   scale_x_log10() +
#   scale_y_log10()
# 
# 
# ggplot(plot_dt, aes(x = Depth, y = nCircs, color = DS)) +
#   # geom_line(aes(group = sample_id)) +
#   geom_point(aes(size = medianBJR, shape = Downsampling)) +
#   scale_color_tableau(direction = -1) +
#   # scale_x_log10() +
#   # scale_y_log10() +
#   facet_wrap(facets = ~ Downsampling, scales = "free")
# 
# 
# ggplot(downsize_stats, aes(x = Depth, y = nCircs, color = DS)) +
#   geom_smooth(aes(group = paste(Downsampling, DS)), se = F, method = "glm") +
#   geom_point(aes(size = medianBJR, shape = Downsampling)) +
#   scale_color_tableau(direction = -1) +
#   scale_x_log10() +
#   scale_y_log10()
```

The lines show how the number of detected features increases with depth. When the number of samples to plot is 1 or 2, bars indicating the number of new features detected when increasing the sequencing depth in one million of reads are also drawn. In that case, lines values are to be read in the left Y axis and bar values in the right Y axis. If more than 2 samples are to be plotted, it is difficult to visualize the new detection bars, so only the lines are shown in the plot.  
Left Y axis shows the number of detected genes with more than 0 counts at each sequencing depth, represented by the lines. The solid point in each line corresponds to the real available sequencing depth. The other sequencing depths are simulated from this total sequencing depth. The bars are associated to the right Y axis and show the number of new features detected per million of new sequenced reads at each sequencing depth.  
The legend in the gray box also indicates the percentage of total features detected with more than k=0 counts at the real sequencing depth.  
Up to twelve samples can be displayed in this plot.  

```{r, fig.width=7, fig.height=5.5}
suppressPackageStartupMessages(library(NOISeq))
mydata_dm1 <- ExpressionSet(assayData = trimmed_source_dataset_l$DM1$counts)
mysaturation_dm1 <- dat(mydata_dm1, k = 0, ndepth = 7, type = "saturation")

mydata_idc <- ExpressionSet(trimmed_source_dataset_l$IDC$counts)
mysaturation_idc <- dat(mydata_idc, k = 0, ndepth = 7, type = "saturation")

mydata_ipf <- ExpressionSet(trimmed_source_dataset_l$IPF$counts)
mysaturation_ipf <- dat(mydata_ipf, k = 0, ndepth = 7, type = "saturation")

mydata_ms <- ExpressionSet(trimmed_source_dataset_l$MS$counts)
mysaturation_ms <- dat(mydata_ms, k = 0, ndepth = 7, type = "saturation")

# mydata_all_sets <- 
#   ExpressionSet(as.matrix(data.frame(dcast(source_ds_dt, 
#                                            formula = circ_id ~ sample_id, 
#                                            value.var = "value", 
#                                            fill = 0), 
#                                      row.names = "circ_id")))
# mysaturation_all_sets <- dat(mydata_all_sets, k = 0, ndepth = 7, type = "saturation")

# explo.plot(mysaturation, toplot = 1, samples = 1:2, yleftlim = NULL, yrightlim = NULL)
# explo.plot(mysaturation, toplot = 1, samples = 1:12, yleftlim = NULL, yrightlim = NULL)
```

```{r}
# depth_dat <- 
#   melt(rbindlist(sapply(mysaturation@dat$depth, 
#                         function(x){data.table(t(x))}, 
#                         simplify = F), 
#                  idcol = "sample_id"), 
#        id.vars = "sample_id", variable.name = "Sampling", value.name = "Depth")
# 
# det_dat <-
#   melt(rbindlist(sapply(mysaturation@dat$saturation$global, 
#                         function(x){data.table(t(x))}, 
#                         simplify = F), 
#                  idcol = "sample_id"), 
#        id.vars = "sample_id", variable.name = "Sampling", value.name = "CircRNAs")
# 
# sat_dat <- merge(depth_dat, det_dat, by = c("sample_id", "Sampling"))
sat_dat <- 
  rbindlist(sapply(list(DM1 = mysaturation_dm1,
                        IDC = mysaturation_idc, 
                        IPF = mysaturation_ipf,
                        MS = mysaturation_ms), 
                   function(mysat){
                     merge(melt(rbindlist(sapply(mysat@dat$depth, 
                                                 function(x){data.table(t(x))}, 
                                                 simplify = F), 
                                          idcol = "sample_id"), 
                                id.vars = "sample_id", variable.name = "Sampling", 
                                value.name = "Depth"),
                           melt(rbindlist(sapply(mysat@dat$saturation$global, 
                                                 function(x){data.table(t(x))}, 
                                                 simplify = F), 
                                          idcol = "sample_id"), 
                                id.vars = "sample_id", variable.name = "Sampling", 
                                value.name = "CircRNAs"), 
                           by = c("sample_id", "Sampling"))
                   }, simplify = F, USE.NAMES = T), 
            idcol = "DS")

sat_dat <- merge(sat_dat, source_ds_meta, by = c("DS", "sample_id"))

ggplot(sat_dat, #[Sampling %in% paste0("V", 1:4)], 
       aes(x = Depth, y = CircRNAs, color = DS)) +
  geom_line(aes(group = sample_id), alpha = .5) +
  geom_point(alpha = 1, shape = 21, fill = "white") +
  geom_point(data = sat_dat[Sampling %in% "V4"], 
             alpha = .75, shape = 21, #size = 2.5, 
             aes(fill = DS)) +
  facet_wrap(facets = ~ DS, scales = "free") +
  scale_color_tableau(direction = -1, guide = "none") +
  scale_fill_tableau(direction = -1, guide = "none") +
  labs(x = "Library size (reads)", y = "Number of circRNAs detected") +
  theme_bw() +
  theme(panel.grid.minor = element_blank())
```


### PCAs {.tabset}

```{r}
# x <- source_ds_dt[circ_id %in% circ_id3s]
# y <- source_ds_meta
# dsname <- "DM1"

plot_pca <- function(dsname, x, y){
    counts <- as.matrix(data.frame(dcast(data = x[DS == dsname], 
                                         formula = circ_id ~ sample_id, 
                                         value.var = "value"), 
                                   row.names = "circ_id"))
    
    sampleTable <- data.frame(y[DS == dsname, .(sample_id, Group = condition)], 
                              row.names = "sample_id")
    
    
    dge <- edgeR::DGEList(counts = counts[, rownames(sampleTable)], group = sampleTable$Group)
    dge <- edgeR::calcNormFactors(dge, method = "TMM")
    cpms <- edgeR::cpm(dge, log = T, prior.count = 1)
    
    pcs <- prcomp(x = t(cpms), scale. = F, center = T)
    var.props <- summary(pcs)$importance[2, ]
    df <- cbind(sampleTable, pcs$x)
    
    ggplot2::ggplot(df, aes(x = PC1, y = PC2, color = Group)) +
        geom_point() +
        labs(x = paste("PC1:", percent(var.props[1])),
             y = paste("PC2:", percent(var.props[2]))) +
        theme_bw()
}
```

```{r}
# source_ds_meta[, .N, by = .(condition)]
source_ds_meta[grepl("normal|control", condition, ignore.case = T), condition := "Normal"]
```

#### DM1

```{r, fig.width=4.5, fig.height=3.5}
plot_pca(dsname = "DM1", x = source_ds_dt[circ_id %in% circ_id3s], y = source_ds_meta) +
    coord_fixed(ratio = 1) +
    theme(legend.position = "top")
```

#### IDC

```{r, fig.width=4.5, fig.height=4.5}
plot_pca(dsname = "IDC", x = source_ds_dt[circ_id %in% circ_id3s], y = source_ds_meta) +
    coord_fixed(ratio = 1) +
    theme(legend.position = "top")
```

#### IPF

```{r, fig.width=4.5, fig.height=4.5}
plot_pca(dsname = "IPF", x = source_ds_dt[circ_id %in% circ_id3s], y = source_ds_meta) +
    coord_fixed(ratio = 1) +
    theme(legend.position = "top")
```

#### MS

```{r, fig.width=4.5, fig.height=4.5}
plot_pca(dsname = "MS", x = source_ds_dt[circ_id %in% circ_id3s], y = source_ds_meta) +
    coord_fixed(ratio = 1) +
    theme(legend.position = "top")
```

### PC data set {.tabset}

```{r}
counts_dt <- fread(PC_data_file,
                   data.table = T,
                   showProgress = F,
                   drop = c("chr", "start", "end", "strand", "gene_id", "circRNA_type"))

## filter the original dataset
counts_dt_m <- melt(counts_dt,
                    id.vars = "circRNA_ID",
                    variable.name = "sample_id",
                    value.name = "BJR")
counts_dt_m[, c("ID", "Group") := tstrsplit(sample_id, "_"), by = sample_id]

## keep only circRNAs expressed in > 2 samples per condition
keep <- counts_dt_m[BJR > 0, .N,
                    by = .(circRNA_ID, Group)][N > 2 &
                                                   Group != "MPC", unique(circRNA_ID)]

## read sample groups
sampleTable <- data.frame(unique(counts_dt_m[Group != "MPC",
                                             .(sample_id, Group)][order(Group, sample_id)]),
                          row.names = "sample_id")

counts <-
    as.matrix(data.frame(counts_dt, check.names = F,
                         row.names = "circRNA_ID"))[keep, rownames(sampleTable)]
# dim(counts)

## check possible biases

dge <- DGEList(counts = counts[, rownames(sampleTable)], group = sampleTable$Group)
dge <- calcNormFactors(dge, method = "TMM")
cpms <- cpm(dge, log = T, prior.count = 1)

pcs <- prcomp(x = t(cpms), scale. = F, center = T)
var.props <- summary(pcs)$importance[2, ]
df <- cbind(sampleTable, pcs$x)
```

#### PCA

```{r, fig.width=4.5, fig.height=3.5}

ggplot2::ggplot(df, aes(x = PC1, y = PC2, color = Group)) +
    geom_point(alpha = .7) +
    scale_color_discrete(labels = c("Normal", "Prostate Cancer"), direction = -1) +
    geom_rect(aes(xmin = -40, xmax = 50, ymin = -30, ymax = 0), 
              fill = NA, 
              color = "red") + 
    annotate(geom = "text", x = 25, y = -5, label = "Batch 2", color = "red") +
    labs(x = paste("PC1:", percent(var.props[1])),
         y = paste("PC2:", percent(var.props[2]))) +
    theme_bw() +
    coord_fixed(ratio = 1) +
    theme(legend.position = "top")
```


```{r}
df$Batch <- ifelse(df$PC2 > 0, "B1", "B2")
sampleTable$Batch <- df[rownames(sampleTable), "Batch"]
## get batch-group sample sizes
table(sampleTable[, c("Batch", "Group")])
```

#### Batch 2

```{r}
## keep only samples from the largest batch
st <- sampleTable[sampleTable$Batch == "B2", "Group", drop = F]
ct <- counts[, rownames(st)]
ct <- ct[rowSums(ct > 0) > 2, ]
dim(ct)

dge.b2 <- DGEList(counts = ct, group = st$Group)
dge.b2 <- calcNormFactors(dge.b2, method = "TMM")
cpms.b2 <- cpm(dge.b2, log = T, prior.count = 1)

pcs.b2 <- prcomp(x = t(cpms.b2), scale. = F, center = T)
var.props.b2 <- summary(pcs.b2)$importance[2, ]
df.b2 <- cbind(st, pcs.b2$x)
```


```{r, fig.width=4.5, fig.height=3.5}
ggplot2::ggplot(df.b2, aes(x = PC1, y = PC2, color = Group)) +
        geom_point() +
        labs(x = paste("PC1:", percent(var.props.b2[1])),
             y = paste("PC2:", percent(var.props.b2[2]))) + 
    scale_color_discrete(labels = c("Normal", "Prostate Cancer"), direction = -1) +
    ggtitle("Batch 2") +
    theme_bw() +
    coord_fixed(ratio = 1) +
    theme(legend.position = "top", plot.title = element_text(hjust = .5))
```

```{r}
pc_cor_g1 <- cor(ct[, rownames(st)[st$Group == "AN"]])
pc_cor_g2 <- cor(ct[, rownames(st)[st$Group == "T"]])

# paste("AN Pearson mean cor =", mean(cor_g1))
# paste("T Pearson mean cor =", mean(cor_g2))
```


```{r}
pc_cor_dt <- rbind(data.table(Group = "G1", CorPear = pc_cor_g1[upper.tri(pc_cor_g1)]),
                   data.table(Group = "G2", CorPear = pc_cor_g2[upper.tri(pc_cor_g2)]))
datatable(pc_cor_dt, rownames = F, filter = "top")
```

```{r}
pc_cor_dt[, .(Min = min(CorPear), Max = max(CorPear)), by = .(Group)]
```

```{r}
datatable(data.table(st, keep.rownames = "Sample"), 
          filter = "top", rownames = F,
          caption = "Batch 2 samples")
```

#### BJR

```{r, fig.width=4, fig.height=2.5}
PC_ds_dt <- data.table(melt(dge.b2$counts))
PC_hist_cnt <- PC_ds_dt[, .(histBJR = .N), 
                        by = .(BJR = value)][, Frac := histBJR / sum(histBJR)][]
plot_dt <- PC_hist_cnt[, .(AvgFrac = mean(Frac)),
                    by = .(BJR)]

PC_ds_stats <- data.table(nSamples = length(unique(PC_ds_dt$Var2)), 
                          nCircs = length(unique(PC_ds_dt$Var1)))

ch_p <- 
    ggplot(plot_dt, aes(x = BJR, y = AvgFrac)) + 
    geom_col(position = "identity", alpha = 1) +
    # facet_wrap(facets = ~ DS, ncol = 1, scales = "free_y") +
    # facet_grid(rows = vars(DS)) +
    coord_cartesian(xlim = c(0, 15)) +
    geom_label(data = PC_ds_stats, 
               size = 3,
               aes(x = 5, y = .5, 
                   label = paste("# samples:", nSamples, "\n# circRNAs:", comma(nCircs))), hjust = 0) +
    labs(x = "Backsplice-junction reads") +
    scale_y_continuous("Count matrix fraction (%)", 
                       labels = function(x)round(as.numeric(x)*100)) + #labels = percent
    scale_x_continuous(breaks = 0:15, 
                       labels = 0:15) +
    scale_fill_tableau(direction = -1) +
    theme_bw() +
    theme(legend.position = "none", 
          axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5), 
          plot.margin = unit(x = c(.1, .1, .1, .1), units = "lines"), 
          strip.text = element_blank(), 
          panel.grid.major.x = element_blank(),
          panel.grid.minor = element_blank(),
          strip.background = element_blank())

ls_bxp <- 
    ggplot(PC_ds_dt[, .(LibSize = sum(value)), by = .(Var2)],
           aes(x = "", y = LibSize)) +
    geom_boxplot(varwidth = T,
                 notch = F,
                 outlier.size = .5) + #, outlier.shape = NA
    # geom_quasirandom(groupOnX = T, varwidth = T, alpha = .5, aes(fill = LibSize), shape = 21) +
    # geom_violin(aes(color = DS), 
    #             trim = T, 
    #             draw_quantiles = c(.25, .5, .75)) +
    # scale_fill_viridis_c() +
    scale_x_discrete(name = NULL) +
    scale_y_log10(labels = function(x)sub("000$", "K", x)) +
    scale_color_tableau(direction = -1) +
    labs(x = NULL, y = "Library size") +
    coord_flip() +
    # facet_wrap(facets = ~ DS, ncol = 1) + #, scales = "free_x"
    # facet_grid(rows = vars(DS)) +
    theme_bw() +
    theme(legend.position = "none",
          axis.ticks.y = element_blank(), 
          panel.grid.major.y = element_blank(),
          plot.margin = unit(x = c(.1, .1, .1, .1), units = "lines"))

ch_p + ls_bxp +
    plot_layout(widths = c(3, 1))
```

# Session info

```{r}
sessionInfo()
```

